{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Dropout, Flatten, SimpleRNN, MaxPooling2D, Input, Dense, Lambda, TimeDistributed, Reshape\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import TerminateOnNaN\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from text_recognizer.datasets.emnist_lines import EmnistLinesDataset\n",
    "from text_recognizer.models.line_rnn import LineLstm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmnistLinesDataset loading data from HDF5...\n"
     ]
    }
   ],
   "source": [
    "dataset = EmnistLinesDataset(max_overlap=0)\n",
    "dataset.load_or_generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSequence(Sequence):\n",
    "    def __init__(self, x, y, batch_size, output_sequence_length):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.output_sequence_length = output_sequence_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = np.take(self.x, range(idx * self.batch_size, (idx + 1) * self.batch_size), axis=0, mode='clip')\n",
    "        batch_y = np.take(self.y, range(idx * self.batch_size, (idx + 1) * self.batch_size), axis=0, mode='clip')\n",
    "        \n",
    "#         batch_y = np.dstack((\n",
    "#             batch_y,\n",
    "#             np.zeros((batch_y.shape[0], batch_y.shape[1]))\n",
    "#         ))\n",
    "        \n",
    "        batch_inputs = {\n",
    "            'image': batch_x,\n",
    "            'y_true': np.argmax(batch_y, -1),\n",
    "            'input_length': np.ones((self.batch_size, 1)) * self.output_sequence_length,\n",
    "            'label_length': np.array([np.where(batch_y[ind, :, -1] == 1)[0][0] for ind in range(self.batch_size)])\n",
    "        }\n",
    "#         batch_outputs = {\n",
    "#             'categorical_crossentropy_loss_output': batch_y,\n",
    "#             'ctc_loss_output': batch_y,\n",
    "#             'acc_output': np.argmax(batch_y, -1)\n",
    "#         }\n",
    "        return batch_inputs, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              (None, 28, 896)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 28, 896, 1)   0           image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 56, 28, 16, 1 0           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 56, 128)      608768      lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)        (None, 56, 128)      32896       time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "y_true (InputLayer)             (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 56, 65)       8385        simple_rnn_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss_output (Lambda)        (None, 1)            0           y_true[0][0]                     \n",
      "                                                                 time_distributed_11[0][0]        \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 650,049\n",
      "Trainable params: 650,049\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1\n",
      "140/625 [=====>........................] - ETA: 3:03 - loss: 50.4071"
     ]
    }
   ],
   "source": [
    "model = LineLstm()\n",
    "\n",
    "def lenet(image_height: int, image_width: int) -> Model:\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(image_height, image_width, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    return model\n",
    "\n",
    "def create_sliding_window_rnn_model(input_shape, max_length, num_classes, window_width, window_stride):\n",
    "    def slide_window(image, window_width=window_width, window_stride=window_stride):\n",
    "        kernel = [1, 1, window_width, 1]\n",
    "        strides = [1, 1, window_stride, 1]\n",
    "        patches = tf.extract_image_patches(image, kernel, strides, [1, 1, 1, 1], 'SAME')\n",
    "        patches = tf.transpose(patches, (0, 2, 1, 3))\n",
    "        patches = tf.expand_dims(patches, -1)\n",
    "        return patches\n",
    "    \n",
    "    image_height, image_width = input_shape    \n",
    "    image_input = Input(shape=input_shape, name='image')\n",
    "    y_true = Input(shape=(max_length,), name='y_true')\n",
    "    input_length = Input(shape=(1,), name='input_length')\n",
    "    label_length = Input(shape=(1,), name='label_length')\n",
    "    \n",
    "    image_reshaped = Reshape((image_height, image_width, 1))(image_input)\n",
    "    image_patches = Lambda(slide_window)(image_reshaped)  # (num_windows, image_height, window_width, 1)\n",
    "    convnet = lenet(image_height, window_width)\n",
    "    convnet_outputs = TimeDistributed(convnet)(image_patches)  # (num_windows, 128)\n",
    "    \n",
    "    # LSTM outputting a single vector\n",
    "    rnn_output = SimpleRNN(128, return_sequences=True)(convnet_outputs) # (sequence_length, 128)\n",
    "    softmaxed_outputs = TimeDistributed(Dense(num_classes, activation='softmax'))(rnn_output)\n",
    "    \n",
    "    ctc_loss_output = Lambda(\n",
    "        lambda x: K.ctc_batch_cost(x[0], x[1], x[2], x[3]),\n",
    "        name='ctc_loss_output'\n",
    "    )([y_true, softmaxed_outputs, input_length, label_length])\n",
    "    \n",
    "    model = Model(inputs=[image_input, y_true, input_length, label_length], outputs=ctc_loss_output)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "dataset_sequence = DatasetSequence(\n",
    "    dataset.x_train,\n",
    "    dataset.y_train,\n",
    "    batch_size=16,\n",
    "    output_sequence_length=56\n",
    ")\n",
    "\n",
    "\n",
    "keras_model = create_sliding_window_rnn_model(\n",
    "    model.input_shape,\n",
    "    model.max_length,\n",
    "    model.num_classes,\n",
    "    32 // 2,\n",
    "    32 // 2\n",
    ")\n",
    "\n",
    "keras_model.compile('rmsprop', loss=lambda yt, yp: yp)\n",
    "keras_model.fit_generator(dataset_sequence, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
